"""
PerceptionNode - Per-drone perception processing node.

Subscribes to camera images, runs YOLO detection + tracking,
and publishes detections for P2P sharing.

Usage:
    ros2 run swarm_ros perception_node --ros-args -p drone_id:=0
"""

from __future__ import annotations

import logging
import math
from typing import TYPE_CHECKING

import rclpy
from rclpy.node import Node
from rclpy.qos import HistoryPolicy, QoSProfile, ReliabilityPolicy
from sensor_msgs.msg import Image

if TYPE_CHECKING:
    pass

logger = logging.getLogger(__name__)


class PerceptionNode(Node):
    """
    ROS2 node for drone perception pipeline.

    Subscribers:
        /drone_N/camera/image (Image) - Camera feed from Gazebo bridge

    Publishers:
        /drone_N/detections (DetectionArray) - Detected objects
    """

    def __init__(self):
        super().__init__("perception_node")

        # Declare parameters
        self.declare_parameter("drone_id", 0)
        self.declare_parameter("model_name", "yolo11n.pt")
        self.declare_parameter("confidence_threshold", 0.4)
        self.declare_parameter("use_gpu", True)
        self.declare_parameter("publish_rate_limit", 10.0)  # Max Hz
        self.declare_parameter("world_name", "perception_test_world")

        self.drone_id = self.get_parameter("drone_id").value
        self.world_name = self.get_parameter("world_name").value
        self.get_logger().info(f"Initializing PerceptionNode for drone {self.drone_id}")

        # Import perception modules
        try:
            from swarm.perception import DetectorConfig, SimpleTracker, YOLODetector
        except ImportError as e:
            self.get_logger().error(f"Failed to import swarm.perception: {e}")
            raise

        # Import ROS2 messages (generated by rosidl)
        try:
            from swarm_ros.msg import Detection as DetectionMsg
            from swarm_ros.msg import DetectionArray

            self._DetectionMsg = DetectionMsg
            self._DetectionArray = DetectionArray
        except ImportError as e:
            self.get_logger().error(
                f"Failed to import swarm_ros messages: {e}. "
                "Did you build the workspace? (colcon build)"
            )
            raise

        # Import cv_bridge for image conversion
        try:
            from cv_bridge import CvBridge

            self.bridge = CvBridge()
        except ImportError as e:
            self.get_logger().error(
                f"Failed to import cv_bridge: {e}. "
                "Install with: sudo apt install ros-jazzy-cv-bridge"
            )
            raise

        # Initialize detector
        config = DetectorConfig(
            model_name=self.get_parameter("model_name").value,
            confidence_threshold=self.get_parameter("confidence_threshold").value,
            use_gpu=self.get_parameter("use_gpu").value,
        )
        self.detector = YOLODetector(config)

        self.get_logger().info("Initializing YOLO detector...")
        if not self.detector.initialize():
            self.get_logger().error("Failed to initialize detector")
            raise RuntimeError("Detector initialization failed")

        self.get_logger().info(f"Detector initialized on {self.detector.device}")

        # Initialize tracker
        self.tracker = SimpleTracker()

        # QoS profiles
        best_effort_qos = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=1,  # Only keep latest frame
        )

        reliable_qos = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            history=HistoryPolicy.KEEP_LAST,
            depth=10,
        )

        # Subscribe to camera image
        # ros_gz_bridge publishes to /drone_N/camera/image
        camera_topic = f"/drone_{self.drone_id}/camera/image"
        self.get_logger().info(f"Subscribing to camera: {camera_topic}")

        self.image_sub = self.create_subscription(
            Image,
            camera_topic,
            self._on_image,
            best_effort_qos,
        )

        # Publisher for detections
        self.detection_pub = self.create_publisher(
            self._DetectionArray,
            f"/drone_{self.drone_id}/detections",
            reliable_qos,
        )

        # State
        self._frame_seq = 0
        self._last_pub_time = self.get_clock().now()
        self._rate_limit = 1.0 / self.get_parameter("publish_rate_limit").value

        # Drone pose (updated externally via subscription or parameter)
        self._drone_position = (0.0, 0.0, 0.0)
        self._drone_yaw = 0.0

        # Subscribe to own drone state for position info
        try:
            from swarm_ros.msg import DroneState

            self.state_sub = self.create_subscription(
                DroneState,
                f"/drone_{self.drone_id}/state",
                self._on_drone_state,
                best_effort_qos,
            )
        except ImportError:
            self.get_logger().warning(
                "DroneState message not available, position tracking disabled"
            )

        # Statistics
        self._total_frames = 0
        self._total_detections = 0
        self._avg_inference_ms = 0.0

        self.get_logger().info(
            f"PerceptionNode started for drone {self.drone_id} "
            f"(device={self.detector.device})"
        )

    def _on_drone_state(self, msg) -> None:
        """Update drone pose from state message."""
        self._drone_position = tuple(msg.position_ned)
        self._drone_yaw = msg.yaw_deg

    def _on_image(self, msg: Image) -> None:
        """Process incoming camera image."""
        # Rate limiting
        now = self.get_clock().now()
        elapsed = (now - self._last_pub_time).nanoseconds / 1e9
        if elapsed < self._rate_limit:
            return

        try:
            # Convert ROS image to OpenCV BGR format
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")

            # Run detection
            detections, inference_ms = self.detector.detect(cv_image)

            # Update tracker
            tracks = self.tracker.update(detections)

            # Build DetectionArray message
            det_array = self._DetectionArray()
            det_array.drone_id = self.drone_id
            det_array.frame_seq = self._frame_seq
            det_array.drone_position_ned = list(self._drone_position)
            det_array.drone_yaw_deg = self._drone_yaw
            det_array.inference_time_ms = inference_ms
            det_array.image_stamp = msg.header.stamp
            det_array.stamp = now.to_msg()

            h, w = cv_image.shape[:2]

            for i, track in enumerate(tracks):
                d = self._DetectionMsg()
                d.drone_id = self.drone_id
                d.track_id = track.track_id
                d.detection_id = i
                d.class_id = track.class_id
                d.class_name = track.class_name
                d.confidence = track.confidence
                d.bbox_x = track.bbox[0]
                d.bbox_y = track.bbox[1]
                d.bbox_width = track.bbox[2]
                d.bbox_height = track.bbox[3]
                d.image_width = w
                d.image_height = h
                # Position estimation not implemented yet
                d.estimated_position_ned = [float("nan")] * 3
                d.position_confidence = 0.0
                d.stamp = now.to_msg()

                det_array.detections.append(d)

            self.detection_pub.publish(det_array)

            # Update statistics
            self._frame_seq += 1
            self._total_frames += 1
            self._total_detections += len(tracks)
            # Exponential moving average for inference time
            alpha = 0.1
            self._avg_inference_ms = (
                alpha * inference_ms + (1 - alpha) * self._avg_inference_ms
            )
            self._last_pub_time = now

            if tracks:
                self.get_logger().debug(
                    f"Frame {self._frame_seq}: {len(tracks)} tracks, "
                    f"{inference_ms:.1f}ms"
                )

        except Exception as e:
            self.get_logger().error(f"Image processing failed: {e}")

    def update_drone_pose(self, position: tuple, yaw: float) -> None:
        """Manually update drone pose for world position estimation."""
        self._drone_position = position
        self._drone_yaw = yaw

    def get_stats(self) -> dict:
        """Get perception statistics."""
        return {
            "drone_id": self.drone_id,
            "total_frames": self._total_frames,
            "total_detections": self._total_detections,
            "avg_inference_ms": self._avg_inference_ms,
            "detector": self.detector.get_stats(),
            "tracker": self.tracker.get_stats(),
        }


def main(args=None):
    """Entry point for perception_node executable."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    rclpy.init(args=args)

    try:
        node = PerceptionNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        logger.error(f"PerceptionNode failed: {e}")
        raise
    finally:
        rclpy.shutdown()


if __name__ == "__main__":
    main()
